from langchain_openai import AzureChatOpenAI
from langchain_openai import AzureOpenAIEmbeddings
import os
from dotenv import load_dotenv

load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("AZURE_OPENAI_API_KEY", "")
embeddings = AzureOpenAIEmbeddings(model=os.getenv("AZURE_OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002"))

llm = AzureChatOpenAI(
    model=os.getenv("AZURE_OPENAI_MODEL_1", "gpt-4"),
    temperature=0,
    api_version="2025-01-01-preview",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", ""),
    azure_deployment=os.getenv("AZURE_OPENAI_MODEL_1", "gpt-4"),
)

from langchain_community.retrievers import AzureAISearchRetriever

retriever = AzureAISearchRetriever(
        service_name=os.getenv("AZURE_AI_SEARCH_SERVICE_NAME", ""),
        top_k=5,
        index_name=os.getenv("AZURE_AI_SEARCH_INDEX_NAME", ""), # ai search ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•  ì¸ë±ìŠ¤ ì´ë¦„
        content_key="chunk", # ê²€ìƒ‰ëœ ê²°ê³¼ì—ì„œ ë¬¸ì„œì˜ page_contentë¡œ ì‚¬ìš©í•  í‚¤, ì£¼ì˜) ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ëŒ€ìƒë  í•„ë“œ ëª…ì´ ì•„ë‹ˆë‹¤.
        api_key=os.getenv("AZURE_AI_SEARCH_API_KEY", "") # Azure Search Service ì˜ key
    )


from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import AzureChatOpenAI

prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì„ ìœ„í•œ ì§€ì›ì í‰ê°€ ë° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë©´ì ‘ê´€ì´ ì§€ì›ìë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ ë„ì›€ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Context: {context}

    Question: {question}"""
    )

llm2 = AzureChatOpenAI(
    model=os.getenv("AZURE_OPENAI_MODEL_1", "gpt-4o"),
    temperature=0,
    api_version="2024-11-20",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", ""),
    azure_deployment=os.getenv("AZURE_OPENAI_MODEL_1", "gpt-4o"),
)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm2
    | StrOutputParser()
)

# í•¨ìˆ˜ë¡œ ë§Œë“¤ì–´ì„œ ë‹¤ë¥¸ ê³³ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•˜ê¸°
def analyze_candidate_profile(question: str) -> str:
    """
    ë©´ì ‘ê´€ì„ ìœ„í•œ ì§€ì›ì í”„ë¡œí•„ ë¶„ì„ í•¨ìˆ˜
    
    Args:
        question: ë©´ì ‘ê´€ì˜ ì§ˆë¬¸ (ì˜ˆ: "ì´ ì§€ì›ìì˜ ê¸°ìˆ  ìŠ¤íƒì´ ë°±ì—”ë“œ ê°œë°œì í¬ì§€ì…˜ì— ì í•©í•œê°€?")
        
    Returns:
        str: AI ë¶„ì„ ê²°ê³¼
    """
    try:
        answer = chain.invoke(question)
        return answer
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_candidate_match(resume_text: str, job_posting_text: str) -> dict:
    """
    ì§€ì›ì-ì±„ìš©ê³µê³  ë§¤ì¹­ ë¶„ì„ (ë©”ì¸ í•¨ìˆ˜)
    
    Args:
        resume_text: ì§€ì›ì ì´ë ¥ì„œ ë‚´ìš©
        job_posting_text: ì±„ìš©ê³µê³  ë‚´ìš©
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ + ì¶”ì²œ ì§ˆë¬¸
    """
    analysis_question = f"""
    ë‹¤ìŒ ì§€ì›ìì™€ ì±„ìš©ê³µê³ ë¥¼ ë¶„ì„í•´ì„œ ê¹”ë”í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:
    
    [ì±„ìš©ê³µê³ ]
    {job_posting_text}
    
    [ì§€ì›ì ì´ë ¥ì„œ]
    {resume_text}
    
    ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
    
    ## ğŸ“Š ì¢…í•© í‰ê°€
    - ì „ë°˜ì  ì í•©ë„: XX/100ì  (í•œì¤„ ìš”ì•½)
    - ê¸°ìˆ  ìŠ¤íƒ ë§¤ì¹­: XX/100ì  (í•µì‹¬ ë§¤ì¹­/ë¶€ì¡± ê¸°ìˆ )
    - ê²½ë ¥ ì¶©ì¡±ë„: XX/100ì  (ìš”êµ¬ì‚¬í•­ ì¶©ì¡± ì—¬ë¶€)
    
    ## âœ… ì£¼ìš” ê°•ì 
    1. [êµ¬ì²´ì  ê°•ì  1]
    2. [êµ¬ì²´ì  ê°•ì  2]  
    3. [êµ¬ì²´ì  ê°•ì  3]
    
    ## âš ï¸ ìš°ë ¤ ì‚¬í•­
    1. [êµ¬ì²´ì  ìš°ë ¤ì  1]
    2. [êµ¬ì²´ì  ìš°ë ¤ì  2]
    3. [êµ¬ì²´ì  ìš°ë ¤ì  3]
    
    ## ğŸ’¬ ì¶”ì²œ ë©´ì ‘ ì§ˆë¬¸ 5ê°€ì§€
    1. [ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸]
    2. [í”„ë¡œì íŠ¸ ê²½í—˜ ì§ˆë¬¸]
    3. [ë¬¸ì œ í•´ê²° ì§ˆë¬¸]
    4. [í˜‘ì—…/ì†Œí†µ ì§ˆë¬¸]
    5. [ì„±ì¥ ê°€ëŠ¥ì„± ì§ˆë¬¸]
    """
    
    result = analyze_candidate_profile(analysis_question)
    return {
        "analysis": result,
        "status": "success"
    }

def ask_specific_question(question: str, resume_text: str = "", job_posting_text: str = "") -> dict:
    """
    íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ (ììœ  ì§ˆì˜ì‘ë‹µ)
    """
    context = ""
    if resume_text:
        context += f"\n[ì´ë ¥ì„œ ì°¸ê³ ]\n{resume_text}"
    if job_posting_text:
        context += f"\n[ì±„ìš©ê³µê³  ì°¸ê³ ]\n{job_posting_text}"
    
    full_question = f"{question}{context}"
    result = analyze_candidate_profile(full_question)
    
    return {
        "type": "specific_question",
        "question": question,
        "answer": result
    }

# ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” ì£¼ì„ ì²˜ë¦¬
# chain.invoke("roundrobin teamì´ë€? ì˜ˆì‹œì½”ë“œ")
