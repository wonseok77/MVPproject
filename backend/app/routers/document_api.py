"""
ë¬¸ì„œ ë¶„ì„ API ë¼ìš°í„° - íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„
"""
import logging
from fastapi import APIRouter, HTTPException, status, UploadFile, File
from pydantic import BaseModel
from ..services.document_analyzer import (
    upload_resume_file, 
    upload_job_posting_file, 
    analyze_candidate_match,
    document_analyzer,
    get_storage_files_list
)

logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(
    prefix="/document",
    tags=["ë¬¸ì„œë¶„ì„"],
    responses={
        404: {"description": "Not found"},
        500: {"description": "Internal server error"}
    }
)

@router.post("/upload-resume")
async def upload_resume_api(file: UploadFile = File(...)):
    """
    ì´ë ¥ì„œ íŒŒì¼ ì—…ë¡œë“œ (1ë‹¨ê³„)
    
    Args:
        file: ì´ë ¥ì„œ íŒŒì¼ (PDF, Word ë“±)
        
    Returns:
        dict: ì—…ë¡œë“œ ê²°ê³¼ (íŒŒì¼ëª… í¬í•¨)
    """
    try:
        filename = file.filename or "unknown_resume.pdf"
        logger.info(f"ì´ë ¥ì„œ ì—…ë¡œë“œ ìš”ì²­: {filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = await file.read()
        
        # Azure Blob Storageì— ì—…ë¡œë“œ
        result = upload_resume_file(file_content, filename)
        
        logger.info(f"ì´ë ¥ì„œ ì—…ë¡œë“œ ì™„ë£Œ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"ì´ë ¥ì„œ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì´ë ¥ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
        )

@router.post("/upload-job")
async def upload_job_posting_api(file: UploadFile = File(...)):
    """
    ì±„ìš©ê³µê³  íŒŒì¼ ì—…ë¡œë“œ (1ë‹¨ê³„)
    
    Args:
        file: ì±„ìš©ê³µê³  íŒŒì¼ (PDF, Word ë“±)
        
    Returns:
        dict: ì—…ë¡œë“œ ê²°ê³¼ (íŒŒì¼ëª… í¬í•¨)
    """
    try:
        filename = file.filename or "unknown_job.pdf"
        logger.info(f"ì±„ìš©ê³µê³  ì—…ë¡œë“œ ìš”ì²­: {filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = await file.read()
        
        # Azure Blob Storageì— ì—…ë¡œë“œ
        result = upload_job_posting_file(file_content, filename)
        
        logger.info(f"ì±„ìš©ê³µê³  ì—…ë¡œë“œ ì™„ë£Œ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"ì±„ìš©ê³µê³  ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì±„ìš©ê³µê³  ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
        )

class AnalyzeFilesRequest(BaseModel):
    resume_filename: str
    job_filename: str

@router.post("/analyze-files")
async def analyze_files_api(request: AnalyzeFilesRequest):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ë“¤ë¡œ ë¶„ì„ ì‹¤í–‰ (2ë‹¨ê³„)
    
    Args:
        request: ë¶„ì„ ìš”ì²­ ë°ì´í„° (ì´ë ¥ì„œ íŒŒì¼ëª…, ì±„ìš©ê³µê³  íŒŒì¼ëª…)
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ (ì í•©ë„, ê°•ì , ìš°ë ¤ì‚¬í•­, ì¶”ì²œì§ˆë¬¸ í¬í•¨)
    """
    try:
        logger.info(f"íŒŒì¼ ë¶„ì„ ìš”ì²­: {request.resume_filename} vs {request.job_filename}")
        
        # íŒŒì¼ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰
        result = analyze_candidate_match(request.resume_filename, request.job_filename)
        
        logger.info("íŒŒì¼ ë¶„ì„ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

class AnalyzeTextRequest(BaseModel):
    resume_text: str
    job_posting_text: str

@router.post("/analyze-text")
async def analyze_text_api(request: AnalyzeTextRequest):
    """
    ì§ì ‘ í…ìŠ¤íŠ¸ë¡œ ë¶„ì„ (íŒŒì¼ ì—†ì´)
    
    Args:
        request: ë¶„ì„ ìš”ì²­ ë°ì´í„° (ì´ë ¥ì„œ ë‚´ìš©, ì±„ìš©ê³µê³  ë‚´ìš©)
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ (ì í•©ë„, ê°•ì , ìš°ë ¤ì‚¬í•­, ì¶”ì²œì§ˆë¬¸ í¬í•¨)
    """
    try:
        logger.info("ì§ì ‘ í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­")
        
        # ì§ì ‘ í…ìŠ¤íŠ¸ ë¶„ì„
        result = document_analyzer.analyze_match(request.resume_text, request.job_posting_text)
        
        logger.info("ì§ì ‘ í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

@router.post("/upload-both")
async def upload_both_files_api(
    resume_file: UploadFile = File(...),
    job_file: UploadFile = File(...)
):
    """
    ì´ë ¥ì„œ + ì±„ìš©ê³µê³  ë™ì‹œ ì—…ë¡œë“œ (í¸ì˜ ê¸°ëŠ¥)
    
    Args:
        resume_file: ì´ë ¥ì„œ íŒŒì¼
        job_file: ì±„ìš©ê³µê³  íŒŒì¼
        
    Returns:
        dict: ë‘ íŒŒì¼ ì—…ë¡œë“œ ê²°ê³¼
    """
    try:
        resume_filename = resume_file.filename or "unknown_resume.pdf"
        job_filename = job_file.filename or "unknown_job.pdf"
        logger.info(f"ë™ì‹œ ì—…ë¡œë“œ ìš”ì²­: {resume_filename}, {job_filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        resume_content = await resume_file.read()
        job_content = await job_file.read()
        
        # ê°ê° ì—…ë¡œë“œ
        resume_result = upload_resume_file(resume_content, resume_filename)
        job_result = upload_job_posting_file(job_content, job_filename)
        
        result = {
            "resume_upload": resume_result,
            "job_upload": job_result,
            "status": "success" if resume_result["status"] == "success" and job_result["status"] == "success" else "error"
        }
        
        logger.info("ë™ì‹œ ì—…ë¡œë“œ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"ë™ì‹œ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë™ì‹œ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
        )

@router.post("/upload-and-analyze")
async def upload_and_analyze_api(
    resume_file: UploadFile = File(...),
    job_file: UploadFile = File(...)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ + ë¶„ì„ í•œ ë²ˆì— ì²˜ë¦¬ (ì˜¬ì¸ì› ê¸°ëŠ¥) - ì‹œì—°ìš© ìµœì í™”
    
    Args:
        resume_file: ì´ë ¥ì„œ íŒŒì¼
        job_file: ì±„ìš©ê³µê³  íŒŒì¼
        
    Returns:
        dict: ì—…ë¡œë“œ ê²°ê³¼ + ë¶„ì„ ê²°ê³¼
    """
    try:
        resume_filename = resume_file.filename or "unknown_resume.pdf"
        job_filename = job_file.filename or "unknown_job.pdf"
        logger.info(f"ğŸš€ ì—…ë¡œë“œ+ë¶„ì„ ìš”ì²­: {resume_filename}, {job_filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        resume_content = await resume_file.read()
        job_content = await job_file.read()
        
        # 1ë‹¨ê³„: ì—…ë¡œë“œ
        logger.info("ğŸ“¤ 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        resume_upload = upload_resume_file(resume_content, resume_filename)
        job_upload = upload_job_posting_file(job_content, job_filename)
        
        if resume_upload["status"] != "success" or job_upload["status"] != "success":
            return {
                "status": "error",
                "message": "íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨",
                "resume_upload": resume_upload,
                "job_upload": job_upload
            }
        
        # 2ë‹¨ê³„: ì¸ë±ì„œ ì¦‰ì‹œ ì‹¤í–‰ (ì‹œì—°ìš© ìµœì í™”)
        logger.info("âš¡ 2ë‹¨ê³„: ì¸ë±ì„œ ì¦‰ì‹œ ì‹¤í–‰ ì¤‘...")
        indexer_result = document_analyzer.run_indexer()
        logger.info(f"   ì¸ë±ì„œ ì‹¤í–‰ ê²°ê³¼: {indexer_result.get('status', 'unknown')}")
        
        # 3ë‹¨ê³„: ì¸ë±ìŠ¤ ì¬ë°œê²¬ (ìƒˆë¡œìš´ ì¸ë±ìŠ¤ê°€ ìƒì„±ë  ìˆ˜ ìˆìŒ)
        logger.info("ğŸ” 3ë‹¨ê³„: ìµœì‹  ì¸ë±ìŠ¤ ì¬ë°œê²¬ ì¤‘...")
        old_index = document_analyzer.index_name
        document_analyzer.index_name = document_analyzer._get_active_index_name()
        
        # ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ë„ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¡œ ì—…ë°ì´íŠ¸
        from azure.search.documents import SearchClient
        document_analyzer.search_client = SearchClient(
            endpoint=document_analyzer.search_endpoint,
            index_name=document_analyzer.index_name,
            credential=document_analyzer.search_credential
        )
        
        if old_index != document_analyzer.index_name:
            logger.info(f"   ì¸ë±ìŠ¤ ë³€ê²½: {old_index} â†’ {document_analyzer.index_name}")
        else:
            logger.info(f"   ê¸°ì¡´ ì¸ë±ìŠ¤ ìœ ì§€: {document_analyzer.index_name}")
        
        # 4ë‹¨ê³„: ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸°
        logger.info("â³ 4ë‹¨ê³„: ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
        from ..services.document_analyzer import wait_for_file_indexing
        import time
        
        # ê° íŒŒì¼ì˜ ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸° (ì‹œì—°ìš©: ìµœëŒ€ 30ì´ˆ)
        resume_indexed = wait_for_file_indexing(f"resume_{resume_filename}", 30)
        job_indexed = wait_for_file_indexing(f"job_{job_filename}", 30)
        
        logger.info(f"   ì¸ë±ì‹± ìƒíƒœ - ì´ë ¥ì„œ: {resume_indexed}, ì±„ìš©ê³µê³ : {job_indexed}")
        
        # 5ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰ (ì¸ë±ì‹± ìƒíƒœì™€ ê´€ê³„ì—†ì´ ì‹œë„)
        logger.info("ğŸ“Š 5ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        if not resume_indexed or not job_indexed:
            logger.warning("âš ï¸ ì¸ë±ì‹± ë¯¸ì™„ë£Œ ìƒíƒœì—ì„œ ë¶„ì„ ì‹œë„...")
            
        analysis_result = analyze_candidate_match(resume_filename, job_filename)
        
        result = {
            "status": "success",
            "upload_results": {
                "resume_upload": resume_upload,
                "job_upload": job_upload
            },
            "indexer_result": indexer_result,
            "index_info": {
                "old_index": old_index,
                "new_index": document_analyzer.index_name,
                "index_changed": old_index != document_analyzer.index_name
            },
            "indexing_status": {
                "resume_indexed": resume_indexed,
                "job_indexed": job_indexed
            },
            "analysis_result": analysis_result
        }
        
        logger.info("âœ… ì—…ë¡œë“œ+ë¶„ì„ ì™„ë£Œ!")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ì—…ë¡œë“œ+ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì—…ë¡œë“œ+ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

@router.post("/upload-and-analyze-fast")
async def upload_and_analyze_fast_api(
    resume_file: UploadFile = File(...),
    job_file: UploadFile = File(...)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ + ë¶„ì„ í•œ ë²ˆì— ì²˜ë¦¬ (ì‹œì—°ìš© ê³ ì† ëª¨ë“œ)
    ì¸ë±ì‹± ëŒ€ê¸° ì‹œê°„ì„ ìµœì†Œí™”í•˜ì—¬ ë¹ ë¥¸ ì‹œì—°ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    
    Args:
        resume_file: ì´ë ¥ì„œ íŒŒì¼
        job_file: ì±„ìš©ê³µê³  íŒŒì¼
        
    Returns:
        dict: ì—…ë¡œë“œ ê²°ê³¼ + ë¶„ì„ ê²°ê³¼
    """
    try:
        resume_filename = resume_file.filename or "unknown_resume.pdf"
        job_filename = job_file.filename or "unknown_job.pdf"
        logger.info(f"ğŸš€ ê³ ì† ì—…ë¡œë“œ+ë¶„ì„ ìš”ì²­: {resume_filename}, {job_filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        resume_content = await resume_file.read()
        job_content = await job_file.read()
        
        # 1ë‹¨ê³„: ì—…ë¡œë“œ
        logger.info("ğŸ“¤ 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        resume_upload = upload_resume_file(resume_content, resume_filename)
        job_upload = upload_job_posting_file(job_content, job_filename)
        
        if resume_upload["status"] != "success" or job_upload["status"] != "success":
            return {
                "status": "error",
                "message": "íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨",
                "resume_upload": resume_upload,
                "job_upload": job_upload
            }
        
        # 2ë‹¨ê³„: ì¸ë±ì„œ ì¦‰ì‹œ ì‹¤í–‰
        logger.info("âš¡ 2ë‹¨ê³„: ì¸ë±ì„œ ì‹¤í–‰ ì¤‘...")
        indexer_result = document_analyzer.run_indexer()
        logger.info(f"   ì¸ë±ì„œ ì‹¤í–‰ ê²°ê³¼: {indexer_result.get('status', 'unknown')}")
        
        # 3ë‹¨ê³„: ì¸ë±ìŠ¤ ì¬ë°œê²¬
        logger.info("ğŸ” 3ë‹¨ê³„: ìµœì‹  ì¸ë±ìŠ¤ ì¬ë°œê²¬ ì¤‘...")
        old_index = document_analyzer.index_name
        document_analyzer.index_name = document_analyzer._get_active_index_name()
        
        # ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ì—…ë°ì´íŠ¸
        from azure.search.documents import SearchClient
        document_analyzer.search_client = SearchClient(
            endpoint=document_analyzer.search_endpoint,
            index_name=document_analyzer.index_name,
            credential=document_analyzer.search_credential
        )
        
        if old_index != document_analyzer.index_name:
            logger.info(f"   ì¸ë±ìŠ¤ ë³€ê²½: {old_index} â†’ {document_analyzer.index_name}")
        else:
            logger.info(f"   ê¸°ì¡´ ì¸ë±ìŠ¤ ìœ ì§€: {document_analyzer.index_name}")
        
        # 4ë‹¨ê³„: ì§§ì€ ì¸ë±ì‹± ëŒ€ê¸° (ì‹œì—°ìš©: ìµœëŒ€ 10ì´ˆ)
        logger.info("â³ 4ë‹¨ê³„: ë¹ ë¥¸ ì¸ë±ì‹± í™•ì¸ ì¤‘...")
        from ..services.document_analyzer import wait_for_file_indexing
        import time
        
        resume_indexed = wait_for_file_indexing(f"resume_{resume_filename}", 10)
        job_indexed = wait_for_file_indexing(f"job_{job_filename}", 10)
        
        logger.info(f"   ë¹ ë¥¸ ì¸ë±ì‹± ìƒíƒœ - ì´ë ¥ì„œ: {resume_indexed}, ì±„ìš©ê³µê³ : {job_indexed}")
        
        # 5ë‹¨ê³„: ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰
        logger.info("ğŸ“Š 5ë‹¨ê³„: ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        analysis_result = analyze_candidate_match(resume_filename, job_filename)
        
        result = {
            "status": "success",
            "mode": "fast",
            "upload_results": {
                "resume_upload": resume_upload,
                "job_upload": job_upload
            },
            "indexer_result": indexer_result,
            "index_info": {
                "old_index": old_index,
                "new_index": document_analyzer.index_name,
                "index_changed": old_index != document_analyzer.index_name
            },
            "indexing_status": {
                "resume_indexed": resume_indexed,
                "job_indexed": job_indexed,
                "wait_time": "10_seconds_max"
            },
            "analysis_result": analysis_result
        }
        
        logger.info("âœ… ê³ ì† ì—…ë¡œë“œ+ë¶„ì„ ì™„ë£Œ!")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ê³ ì† ì—…ë¡œë“œ+ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ê³ ì† ì—…ë¡œë“œ+ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

@router.get("/files-list")
async def get_files_list_api():
    """
    Azure Blob Storageì— ìˆëŠ” íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    
    Returns:
        dict: ì´ë ¥ì„œ ë° ì±„ìš©ê³µê³  íŒŒì¼ ëª©ë¡
    """
    try:
        logger.info("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ìš”ì²­")
        
        result = get_storage_files_list()
        
        logger.info(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {result.get('total_files', 0)}ê°œ")
        return result
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        ) 

@router.get("/debug-index")
async def debug_index_api():
    """
    Azure AI Search ì¸ë±ìŠ¤ ë””ë²„ê¹… (ê°œë°œìš©)
    
    Returns:
        dict: ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆì™€ ëª¨ë“  ë¬¸ì„œ ì •ë³´
    """
    try:
        logger.info("ì¸ë±ìŠ¤ ë””ë²„ê¹… ìš”ì²­")
        
        result = document_analyzer.debug_search_index()
        
        logger.info("ì¸ë±ìŠ¤ ë””ë²„ê¹… ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"ì¸ë±ìŠ¤ ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì¸ë±ìŠ¤ ë””ë²„ê¹… ì‹¤íŒ¨: {str(e)}"
        ) 

@router.post("/run-indexer")
async def run_indexer_api():
    """
    Azure AI Search ì¸ë±ì„œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰ (Blob Storage â†’ AI Search ë™ê¸°í™”)
    
    Returns:
        dict: ì¸ë±ì„œ ì‹¤í–‰ ê²°ê³¼
    """
    try:
        logger.info("ì¸ë±ì„œ ìˆ˜ë™ ì‹¤í–‰ ìš”ì²­")
        
        result = document_analyzer.run_indexer()
        
        logger.info(f"ì¸ë±ì„œ ì‹¤í–‰ ì™„ë£Œ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"ì¸ë±ì„œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì¸ë±ì„œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )

@router.get("/indexer-status")
async def get_indexer_status_api():
    """
    Azure AI Search ì¸ë±ì„œ ìƒíƒœ í™•ì¸
    
    Returns:
        dict: ëª¨ë“  ì¸ë±ì„œì˜ ìƒíƒœ ì •ë³´
    """
    try:
        logger.info("ì¸ë±ì„œ ìƒíƒœ í™•ì¸ ìš”ì²­")
        
        result = document_analyzer.check_indexer_status()
        
        logger.info("ì¸ë±ì„œ ìƒíƒœ í™•ì¸ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"ì¸ë±ì„œ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì¸ë±ì„œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}"
        ) 